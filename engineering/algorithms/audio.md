# audio

### å·¥å…·

* librosa
* pyaudio
* scipy.io.wave
* pydub.AudioSegment
* PyAstronomy
* pyAudioAnalysis

### [i-vector](http://cslt.riit.tsinghua.edu.cn/mediawiki/images/c/cb/131104-ivector-microsoft-wj.pdf)

GMM-UBM framework \[D. A. Reynolds, 2000\]

Speaker verification\[S. Furui, 1981; D. A. Reynolds, 2003\]ï¼što verify a speech utterance belongs to a specified enrollment, accept or reject.

i-vector \[N. Dehak, 2011\] 

ğ‘€ = ğ‘š + ğ‘‡w, T is a low rank ğ¶ğ¹ Ã— ğ‘… subspace that contains the eigenvectors with the largest eigenvalues of total variability covariance matrix. w~ğ‘\(0,ğ¼\)



### Music information retrieval \(MIR\)

### å£°çº¹

Speaker verification \(SV\) is the process of verifying whether an utterance belongs to a specific speaker, based on that speakerâ€™s known utterances \(i.e., enrollment utterances\), with applications such as Voice Match.

Depending on the restrictions of the utterances used for enrollment and verification, speaker verification models usually fall into one of two categories: text-dependent speaker verification \(TD-SV\) and text-independent speaker verification \(TI-SV\).

speaker recognition

speaker diarization

è¯´è¯äººè¯†åˆ«\(SRE\)

å£°çº¹è¯†åˆ«\(VPR\)

GMM-UBM\(Universal Background Model, é€šç”¨èƒŒæ™¯æ¨¡å‹\) -&gt;

Joint Factor Analysis, JFAç®—æ³• -&gt; å…¨å˜é‡ç³»ç»Ÿ\(Total Variability\) -&gt; i-vector

### éŸ³è‰²ä¸é¢‘ç‡

è°æ³¢

### éŸ³é¢‘è´¨é‡ audio quality

PESQ - FR\(Full reference\)

looking for a NR\(Non reference\) implementation

Mean Opinion Score \(MOS\)

ä¿¡å™ªæ¯”ä¼°è®¡ PyAstronomy

Noise-Estimation Algorithms

1. é€’å½’å¹³å‡å™ªå£°ç®—æ³•
2. æœ€å°å€¼è·Ÿè¸ªç®—æ³•
3. ç›´æ–¹å›¾å™ªå£°ä¼°è®¡ç®—æ³•

### éŸ³é¢‘ç‰¹å¾ [python](https://www.kaggle.com/varanr/audio-feature-extraction)

**åŠŸç‡è°±å¯†åº¦ä¸é¢‘ç‡å…³ç³»** ï¼ˆç²‰çº¢å™ªéŸ³-ä½é¢‘é«˜åŠŸç‡ï¼‰

**å…‰è°±è´¨å¿ƒ**

**å…‰è°±è¡°å‡**

\*\*\*\*[**Filter bank\(fbank\)å’Œmfcc by python**](https://haythamfayek.com/2016/04/21/speech-processing-for-machine-learning.html)

**è‰²åº¦é¢‘ç‡\(å…«åº¦\)**

x, sr = librosa.load\('../simple\_piano.wav'\)

hop\_length = 512

chromagram = librosa.feature.chroma\_stft\(x, sr=sr, hop\_length=hop\_length\)

librosa.display.specshow\(chromagram, x\_axis='time', y\_axis='chroma', hop\_length=hop\_length, cmap='coolwarm'\)

### äººå£°ä¼´å¥åˆ†ç¦»æå–

```python
S_full, phase = librosa.magphase(librosa.stft(x[10000:80000]))
# nearest neighbor
S_filter = librosa.decompose.nn_filter(S_full,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â aggregate=np.median,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â metric='cosine',
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â width=int(librosa.time_to_frames(2, sr=sr)))
S_filter = np.minimum(S_full, S_filter)

# instrumentation mask margin and vocals mask margin
margin_i, margin_v = 2, 10
power = 2
# softmask(X, X_ref, power=1, split_zeros=False)
#   `M = X**power / (X**power + X_ref**power)`
mask_i = librosa.util.softmask(S_filter,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â margin_i * (S_full - S_filter),
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â power=power)

mask_v = librosa.util.softmask(S_full - S_filter,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â margin_v * S_filter,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â power=power)
S_foreground = mask_v * S_full
S_background = mask_i * S_full

# listern to the seperation result
y=librosa.istft(S_background*phase)

```





