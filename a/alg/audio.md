# audio

### å·¥å…·

* librosa
* pyaudio
* scipy.io.wave
* pydub.AudioSegment
* PyAstronomy
* pyAudioAnalysis

### 

### Music information retrieval \(MIR\)

### å£°çº¹

Speaker verification \(SV\) is the process of verifying whether an utterance belongs to a specific speaker, based on that speakerâ€™s known utterances \(i.e., enrollment utterances\), with applications such as Voice Match.

æµŠéŸ³çš„å‰ä¸‰ä¸ªå…±æŒ¯å³°ï¼ˆformantï¼‰å¯¹è¯´è¯äººä¸ªæ€§ç‰¹å¾ä½“ç°è¾ƒæ˜æ˜¾ï¼Œè€Œå‰ä¸¤ä¸ªå¯¹äºåŒºåˆ«è¯­éŸ³å†…å®¹ä½“ç°æ˜æ˜¾ã€‚

Depending on the restrictions of the utterances used for enrollment and verification, speaker verification models usually fall into one of two categories: text-dependent speaker verification \(TD-SV\) and text-independent speaker verification \(TI-SV\).

speaker recognition

speaker diarization

è¯´è¯äººè¯†åˆ«\(SRE\)

å£°çº¹è¯†åˆ«\(VPR\)

[i-vector](http://cslt.riit.tsinghua.edu.cn/mediawiki/images/c/cb/131104-ivector-microsoft-wj.pdf) \[N. Dehak, 2011\]; GMM-UBM framework \[D. A. Reynolds, 2000\] GMM-UBM\(Universal Background Model, é€šç”¨èƒŒæ™¯æ¨¡å‹\) -&gt;Joint Factor Analysis, JFAç®—æ³• -&gt; å…¨å˜é‡ç³»ç»Ÿ\(Total Variability\) -&gt; i-vector  
ğ‘€ = ğ‘š + ğ‘‡w, T is a low rank ğ¶ğ¹ Ã— ğ‘… subspace that contains the eigenvectors with the largest eigenvalues of **total variability \(tv\) covariance matrix**. w~ğ‘\(0,ğ¼\)

DNN : x-vector, \(via äººè„¸è¯†åˆ«\) Triplet loss, center loss etc.  
Margin Loss such as ASoftmax/ArcSoftmax\(å‡åŒ€è¶…çƒé¢ç±»é—´è·\)

å£°çº¹åä½œå¼Š

ref:  
éŸ³è‰²ä¸é¢‘ç‡: è°æ³¢

### è¯­éŸ³ç†è§£ã€ç”Ÿæˆ

Connectionist Temporal Classification \(CTC\): TDNN \(OCR task as example\)

TTS: WaveNet \(NN vocoder\) to TocoTron2 \(32X32X2 to 128X128X2\) to WaveRNN \(1-D conv to RNN, only relying on the last sample\) to LPCNet \(a WaveRNN variant, efficient speech synthesis\)ã€LAS \(Listen, Attend and Spell\) network

è¯­éŸ³è½¬åŒ–/è½¬å†™ - Voice Conversion: StarGAN

### éŸ³é¢‘è´¨é‡ audio quality

PESQ - FR\(Full reference\)

looking for a NR\(Non reference\) implementation

Mean Opinion Score \(MOS\)

ä¿¡å™ªæ¯”ä¼°è®¡ PyAstronomy, WADA SNR est

Noise-Estimation Algorithms

1. é€’å½’å¹³å‡å™ªå£°ç®—æ³•
2. æœ€å°å€¼è·Ÿè¸ªç®—æ³•
3. ç›´æ–¹å›¾å™ªå£°ä¼°è®¡ç®—æ³•

### éŸ³é¢‘ç‰¹å¾ [python](https://www.kaggle.com/varanr/audio-feature-extraction)

**åŠŸç‡è°±å¯†åº¦ä¸é¢‘ç‡å…³ç³»** ï¼ˆç²‰çº¢å™ªéŸ³-ä½é¢‘é«˜åŠŸç‡ï¼Œæ¸…éŸ³åŠŸç‡è¿œå°äºæµŠéŸ³ï¼‰

**Formant \(å…±æŒ¯å³°\)** - \(åŸºé¢‘ - è°æŒ¯ï¼Œæ³›éŸ³ä¸»è¦é¢‘ç‡å³°\)

**Pitchï¼ˆåŸºé¢‘ï¼‰**- å£°å¸¦æŒ¯åŠ¨ - å‡†å‘¨æœŸæµŠéŸ³ï¼ˆvsæ¸…éŸ³ï¼Œå£°å¸¦ä¸æŒ¯åŠ¨ï¼Œå…ƒéŸ³éƒ½æ˜¯æµŠéŸ³ï¼Œè¾…éŸ³éƒ½æœ‰ï¼‰

**å…‰è°±è´¨å¿ƒ**

**å…‰è°±è¡°å‡**

\*\*\*\*[**Filter bank\(fbank\)å’Œmfcc by python**](https://haythamfayek.com/2016/04/21/speech-processing-for-machine-learning.html)

**è‰²åº¦é¢‘ç‡\(å…«åº¦\)**

x, sr = librosa.load\('../simple\_piano.wav'\)

hop\_length = 512

chromagram = librosa.feature.chroma\_stft\(x, sr=sr, hop\_length=hop\_length\)

librosa.display.specshow\(chromagram, x\_axis='time', y\_axis='chroma', hop\_length=hop\_length, cmap='coolwarm'\)

### äººå£°ä¼´å¥åˆ†ç¦»æå–

```python
S_full, phase = librosa.magphase(librosa.stft(x[10000:80000]))
# nearest neighbor
S_filter = librosa.decompose.nn_filter(S_full,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â aggregate=np.median,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â metric='cosine',
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â width=int(librosa.time_to_frames(2, sr=sr)))
S_filter = np.minimum(S_full, S_filter)

# instrumentation mask margin and vocals mask margin
margin_i, margin_v = 2, 10
power = 2
# softmask(X, X_ref, power=1, split_zeros=False)
#   `M = X**power / (X**power + X_ref**power)`
mask_i = librosa.util.softmask(S_filter,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â margin_i * (S_full - S_filter),
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â power=power)

mask_v = librosa.util.softmask(S_full - S_filter,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â margin_v * S_filter,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â power=power)
S_foreground = mask_v * S_full
S_background = mask_i * S_full

# listern to the seperation result
y=librosa.istft(S_background*phase)

```





